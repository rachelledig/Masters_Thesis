`fr if(knitr:::is_latex_output()) '\\appendix'`

`r if(!knitr:::is_latex_output()) '# (APPENDIX) Appendix {-}'`

# Appendix

## Proof of Bayes' Theorem for Two Hypothesis from @hackingIntroductionProbabilityInductive2001 {#bayesproof}

Definition of **Conditional Probability** taken from @hackingIntroductionProbabilityInductive2001 beginning on p.49:

```{=tex}
\begin{equation}
\text{Pr(A|B)}= \frac{\text{Pr(A,B)}}{\text{Pr(B)}} 
(\#eq:conditionalprob)
\end{equation}
```
Implying that for $\text{Pr(B) > 0}$,

```{=tex}
\begin{equation}
\text{Pr(A|B)} * \text{Pr(B)} = \text{Pr(A,B)}  
(\#eq:conditionalprobproof1)
\end{equation}
```
Knowing that,

```{=tex}
\begin{equation}
\text{Pr(B,A)} = \text{Pr(A,B)} 
(\#eq:conditionalprobproof2)
\end{equation}
```
Therefore,

```{=tex}
\begin{equation}
\text{Pr(B|A)} * \text{Pr(A)} = \text{Pr(A|B)} * \text{Pr(B)} 
(\#eq:conditionalprobproof3)
\end{equation}
```
Dividing by $\text{P(A)}$, gives Bayes' Theorem (equivalent to Equation \@ref(eq:bayesmath))

```{=tex}
\begin{equation}
\text{Pr(B|A)}= \frac{\text{Pr(A|B) * Pr(B)}}{\text{Pr(A)}} 
(\#eq:bayes)
\end{equation}
```
Assuming that $0 < \text{Pr(B)} < 1$, the equation for **Total Probability** taken from @hackingIntroductionProbabilityInductive2001 [p.59] can be written:

```{=tex}
\begin{equation}
\text{Pr(A)} = \text{Pr(A|B)} * \text{Pr(B)} + \text{Pr(A|Not B)} * \text{Pr(Not B)}
(\#eq:totalprob)
\end{equation}
```
Substituting Equation \@ref(eq:totalprob) into Equation \@ref(eq:bayes), giving rise to the Equation \@ref(eq:twohypothesis), the base equation used for the basis of Equation \@ref(eq:bayesspecial),

```{=tex}
\begin{equation}
\text{Pr(B|A)}= \frac{\text{Pr(A|B) * Pr(B)}}{\text{Pr(A|B)} * \text{Pr(B)} + \text{Pr(A|Not B)} * \text{Pr(Not B)}} 
(\#eq:twohypothesis)
\end{equation}
```

### Bayes Theorem {#bayesthe}

Bayes' theorem is the basis for Bayesian inference. Although Bayes' theorem can be manipulated in to many forms, the most basic representation is Equation \@ref(eq:bayesmath).

```{=tex}
\begin{equation}
p(\theta|y) = \frac{ p(y|\theta) * p(\theta)}{p(y)}
(\#eq:bayesmath)
\end{equation}
```
Where $\theta$ is an unknown parameter to be estimated and $y$ is the observed data. To understand the what is happening here, it is necessary to define some terms using accessible language from @mcelreathStatisticalRethinkingBayesian2020 [p. 37].

-   The symbol \| can be read as "given" or "conditional on", meaning that the probability of one event is dependent on the occurrence of another. This is also known ask "Conditional Probability".

-   The outcome $p(\theta|y)$, is also known as the "posterior" and can be read as "the probability of a the unobserved parameter given the observed data".

-   $p(y|\theta)$ is the probability of the data, or the likelihood.

-   $p(\theta)$, represents previous knowledge about the unobserved parameter $\theta$, and is called the "prior".

-   $p(y)$ is the "average probability of the data", which is "the probability of the data, that has been averaged over $p(\theta)$", as @mcelreathStatisticalRethinkingBayesian2020 [p. 37] mentions. The main function of $p(y)$ is to normalize the posterior (remember, $p(\theta|y)$).

All together Bayes' theorem looks like this [@mcelreathStatisticalRethinkingBayesian2020]:

```{=tex}
\begin{equation}
\text{Posterior} = \frac{\text{Probability of the Data} * \text{Prior}}{\text{Average Probability of the Data}}
(\#eq:bayesword)
\end{equation}
```
It is important to remember that although Bayes' theorem can be used with point estimates[^1], the advantage of Bayesian inference is that all terms in Equation \@ref(eq:bayesmath) can be represented as probability distributions, communicating much more uncertainty about a parameter than point estimate statistics. From this point forward, assume that terms such as posterior, prior, and likelihood imply distributions not point estimates. For fun, a relevant example of a point estimate use of Bayes Theorem is listed in Section \@ref(covidex).

[^1]: A point estimate is a single value, generally the average, given as the estimate value for a parameter.

Even more so when using probability distributions, often times it is difficult to deal with the normalizing term, $p(y)$. However, as $p(y)$ does not depend on the unobserved parameter $\theta$, it can be considered a constant and factored out giving rise to the more common used and less computationally difficult *unnormalized posterior density* [@mcelreathStatisticalRethinkingBayesian2020; @gelmanBayesianDataAnalysis2013]*.*

```{=tex}
\begin{equation}
p(\theta|y) \propto p(y|\theta) * p(\theta)
(\#eq:proppost)
\end{equation}
```
Effectively, Equation \@ref(eq:proppost) means that the posterior is proportional to the likelihood, $p(y|\theta)$, multiplied by the prior, $p(\theta)$. Its not necessary in most contexts to normalize using $p(y)$, proportionality works just fine.

#### The Prior

Specification of the prior distribution is not a trivial task, as the prior attempts to encapsulate the previous knowledge of a specific parameter and has impacts on the posterior distribution. The determination of the prior should be done before seeing the data and serves two main functions, communicating previous scientific or common knowledge about a parameters distribution and/or helping the the model learn more efficiently [@mcelreathStatisticalRethinkingBayesian2020]. Often times flat priors are used initially and improved upon iteratively. Effects of the prior on the posterior can be seen in Figure \@ref(fig:prioreffects) which is adapted from @mcelreathStatisticalRethinkingBayesian2020 [p. 38] and @kurzStatisticalRethinkingBrms2019 [sec. 2.4].

```{r warning=FALSE, message=FALSE, echo=FALSE}
sequence_length <- 1e3

d <-
  tibble(probability = seq(from = 0, to = 1, length.out = sequence_length)) %>% 
  expand(probability, row = c("flat", "beta", "exponential")) %>% 
  arrange(row, probability) %>% 
  mutate(prior = ifelse(row == "flat", 1,
                        ifelse(row == "beta", dbeta(probability, shape1 = 0.75, shape2 = 0.75),
                               dexp(probability, rate = 5))),
         likelihood = dnorm(probability, mean = 0.5, sd = 0.25)) %>% 
  group_by(row) %>% 
  mutate(posterior = prior * likelihood) %>% 
  gather(key, value, -probability, -row) %>% 
  ungroup() %>% 
  mutate(key = factor(key, levels = c("prior", "likelihood", "posterior")),
         row = factor(row, levels = c("flat", "beta", "exponential")))
```

```{r prioreffects, warning=FALSE, message=FALSE, echo=FALSE, fig.cap= "Effects of the prior distrubution on the unnormalized posterior with a Normal(0.5, 0.25) likelihood. First row: Uniform prior, Second row: Beta(a = 0.75, b = 0.75) prior, Third Row: Exponential prior. Prior and likelihood are multiplied together to create the unnormalized posterior seen in the third column."}
p1 <-
  d %>%
  filter(key == "prior") %>% 
  ggplot(aes(x = probability, y = value)) +
  geom_line() +
  scale_x_continuous(NULL, breaks = c(0, .5, 1)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "prior") +
  theme(panel.grid       = element_blank(),
        strip.background = element_blank(),
        strip.text       = element_blank()) +
  facet_wrap(row ~ ., scales = "free_y", ncol = 1)

p2 <-
  d %>%
  filter(key == "likelihood") %>% 
  ggplot(aes(x = probability, y = value)) +
  geom_line() +
  scale_x_continuous(NULL, breaks = c(0, .5, 1)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "likelihood") +
  theme(panel.grid       = element_blank(),
        strip.background = element_blank(),
        strip.text       = element_blank()) +
  facet_wrap(row ~ ., scales = "free_y", ncol = 1)

p3 <-
  d %>%
  filter(key == "posterior") %>% 
  ggplot(aes(x = probability, y = value)) +
  geom_line() +
  scale_x_continuous(NULL, breaks = c(0, .5, 1)) +
  scale_y_continuous(NULL, breaks = NULL) +
  labs(subtitle = "posterior") +
  theme(panel.grid       = element_blank(),
        strip.background = element_blank(),
        strip.text       = element_blank()) +
  facet_wrap(row ~ ., scales = "free_y", ncol = 1)

library(gridExtra)

grid.arrange(p1, p2, p3, ncol = 3)
```

There are several different types of priors used when discussing Bayesian inference. Some of the most common types of priors discussed are [@gelmanBayesianDataAnalysis2013]:

-   **Proper priors,** which integrate to 1 and **improper priors,** that don't. The fact that a prior (or any probability distribution for that matter) integrates to 1 is important not only computationally, as it makes it easier to manipulate and solve analytically, but an improper prior violates the assumption that probability distributions integrate to 1.

-   **Informative priors** communicate information about a given parameter's distribution, **non-informative priors** do not. A classic example of a non informative prior is a flat or uniform prior (seen in the row 1 of Section \@ref(fig:prioreffects)) as it assumes that all probability values are equally likely which is almost never the case.

-   To discuss the amount of information communicated via the prior distribution to the posterior, terms such as **Strongly Informative Priors** or **Weakly Informative Priors** can be used. Weakly informative priors are informative (i.e. they do contain information about the distribution of a given parameter) but serve to regularize the posterior only by setting bounds within which the posterior can vary its shape, meaning that they are not aiming to completely describe the distribution of a parameter. In addition, these priors are easily overwhelmed if the amount of data is large. Strongly informative priors, conversely, heavily influence the posterior distribution and are more likely to overwhelm the data.

The goal when specifying the prior is to have at least a weakly informative prior for each given parameter. This ensures that general scientific knowledge about the distribution of a parameter is communicated but if large amounts of data exist, the prior gives way to the overwhelming evidence of the likelihood [@gelmanPriorChoiceRecommendations2020]. Manipulation of the prior can be useful from can be used to solve or diagnose issues, given certain contexts and questions. However, it is important to note that "bad" (less suitable) priors can come with some unintended consequences such as allowing for more unstable predictions due sampling difficulties from bad geometry of the posterior (when using tools such as STAN [@standevelopmentteamRStanInterfaceStan2020]) or entertaining predictions that are not possible given the problem (ex. predicting negative values when logically only positive ones exist) [@mcelreathStatisticalRethinkingBayesian2020, sec. 5.1]. Priors that are skeptical of extreme values are often times called *regularizing* priors [@mcelreathStatisticalRethinkingBayesian2020, sec. 7.5]

@gelmanPriorCanOften2017 and @gelmanPriorChoiceRecommendations2020 discuss appropriate prior choice and emphasize that the identification of weak or strong priors is not possible without knowledge of the likelihood, which violates the idea that a prior should be constructed *a priori,* or before having any notion of the data or even the data generating process. As mentioned in @gelmanPriorCanOften2017 [sec. 1.2], this may be the most ideal way to construct a prior but in reality practical concerns such as model convergence, unknown parameters, knowledge of the modeler, etc. make this task impossible or very difficult. Hence, a division is created that separates Bayesian issues into two camps, those can/are willing to build a prior in a *subjective* way by incorporating expert/scientific knowledge into the prior *before* seeing the data or setting up the model, and those that "break" this rule by using some knowledge about the likelihood and data to construct their prior.

Ultimately, prior specification for Bayesian inference is necessary but is often times more of an art than a science. Iterative processes help with choosing the prior and seeing its effect on the posterior for a given question, dataset, and model. The overall aim is to balance practical and theoretical concerns when choosing most the suitable prior. Currently, a large area of research focuses solely on prior specification and usage within a Bayesian context aimed at demystifying prior specification and increasing standardization of prior specification processes and documentation.

### Model Comparison

Multiple ways to compare models exist, some rely more heavily on a conceptual and causal understanding of the problem, others rely on predictive accuracy. Model comparison can occur *within-sample* or *out-of-sample,* meaning that comparisons calculated using data used to train the model (*within-sample*) or using data that has been left our when fitting the model (*out-of-sample*).

More informal methods of model comparison exist such as prior and posterior predictive checks, comparison of bayes' factor or bayesian $R^2$ among others. [@gelmanUnderstandingPredictiveInformation2014]. However, as these checks are done using within-sample data, and some can be prone to overfitting under certain circumstances [@mcelreathStatisticalRethinkingBayesian2020, chap. 7]

## Digression: Covid Rapid Antigen Tests {#covidex}

Imagine (you don't have to) that SARS-CoV-2 is circulating in Berlin. An individual takes a rapid antigen test and receives a positive test result. However, the media recently has been discussing that rapid antigen tests are less accurate than other types of tests to detect SARS-CoV-2, like the PCR. The individual thinks that perhaps the test was wrong, meaning that this person received a "false positive" and doesn't actually have Covid even though the test came back positive. Data can be gathered, a positive test result (the $y$), and a hypothesis can be constructed, the individual doesn't have Covid (the $\theta$). Substituting this in to Bayes' theorem, the probability that this individual doesn't have Covid even though the test came back positive can be calculated (remember, $p(\theta|y)$) using Equation \@ref(eq:covidword).

```{=tex}
\begin{equation}
\text{p(No Covid|Pos)} = \frac{\text{p(Pos|No Covid)} * \text{p(No Covid)}}{\text{p(Pos)}}
(\#eq:covidword)
\end{equation}
```
Some extra information is necessary to fill in the missing pieces,

-   According to @tagesspiegelCoronavirusKarteDeutschlandweiteFallzahlen2021, 200 people are infected with SARS-CoV-2 for every 100,000 people in Berlin, also known as probability of having Covid ($\text{P(Covid)} = 0.002$). Since our hypothesis is that the individual *doesn't* have Covid, we can calculate $\text{P(No Covid)} = 0.998$. This represents our previous knowledge about how many people don't have Covid and is the prior ($p(\theta)$) in Bayes' theorem.

-   My local [Covid Test Center](https://schnell.coronatest.de/?lang=en) claims that their rapid antigen tests have a sensitivity of 96% and a specificity of 99%. Sensitivity is the ability to correctly identify those who have the disease and specificity is the ability to correctly identify those that do not have the disease.

    -   So sensitivity represents the probability of testing positive when (or *given*) you have Covid, $\text{P(Positive|Covid)} = 0.96$. Conversely, the $\text{P(Negitive|Covid)} = 0.04$
    -   Specificity represents the probability of testing negative given you don't have Covid $\text{P(Negative|No Covid)} = 0.99$. Then, $\text{P(Positive|No Covid)} = 0.01$. This is the probability of the data, or the likelihood $(p(y|\theta))$.

From these statements, Table \@ref(tab:makingcovid) can be created .

```{r makingcovid, echo=FALSE, fig.pos='H'}
x <- c("0.96", "0.04", "0.01", "0.99")
dim(x) <- c(2,2)
colnames(x) <- c("Covid (p = 0.002)", "No Covid (p = 0.998)")
rownames(x) <- c("Positive", "Negative")
kable(x, booktabs = TRUE, caption="\\label{tab:makingcovid}Probabilities for incidence of Covid and rapid antigen test sensitivity.") %>% 
  kable_styling(full_width = F, latex_options = "HOLD_position") 
```

Last thing that needs to be discussed is the denominator, $\text{p(Positive)}$ or $p(y)$. There is a manipulation of Bayes's rule using the law of Conditional Probability detailed in @hackingIntroductionProbabilityInductive2001 that can be used in cases where there are only two outcomes (two $\theta$s ). This can be applied here as is this the case, i.e. the person either has or doesn't have Covid. Equation @ref(eq:bayesspecial) details @hackingIntroductionProbabilityInductive2001 for this example. Proof for @ref(eq:bayesspecial) can be seen in \@ref(bayesproof).

```{=tex}
\begin{equation}
P(\text{No Covid|Pos}) = \frac{\text{P(Pos|No Covid)} * \text{P(No Covid)}}{\text{P(Pos|No Covid)} * \text{P(No Covid)} + \text{P(Pos|Covid)} * \text{P(Covid)}}
(\#eq:bayesspecial)
\end{equation}
```
From then using Table \@ref(tab:makingcovid) and Equation \@ref(eq:bayesspecial), the probability of not having Covid given a positive test result can be calculated.

```{=tex}
\begin{align}
P(\text{No Covid|Pos}) &= \frac{0.01 * 0.998}{0.01 * 0.998 + 0.96 * 0.002} \\
P(\text{No Covid|Pos}) &= 0.84
(\#eq:bayesmath2)
\end{align}
```
So, what does this mean? This $\text{P(No Covid|Pos)} = 0.84$ is the probability of not having Covid given a positive test result. This is quite high, so chances are even though the test came back positive, this individual does not have Covid. Perhaps we should take another rapid test or a PCR.

## Predictor Selection {#predselect}
